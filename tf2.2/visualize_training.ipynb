{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network (FCN) Training (Tensorflow 2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook it is demonstrated how to train a deep learning (DL) model built using an fully convolutional network(FCN) architecture to predict the column heights (CHs) in high entropy alloys (HEAs) using Tensorflow 2.2.0\n",
    "\n",
    "Given the complexity of the problem, we realized that parallel compution is mandatory, since the learning process to accurately predict the CHs for each element requires a substantial amount of epochs. There two ways to implement a parallel DL calculation: **data parallelization** and **model parallelization**. Data parallelization is implemented using the **Mirrored Strategy** method from Tensorflow. A detailed explaination of data parallelization using Mirrored Strategy is provided here:\n",
    "\n",
    "**Mirrored Stategy (Data Parallelization)**:  https://www.tensorflow.org/tutorials/distribute/custom_training\n",
    "\n",
    "\n",
    "Model parallelization is implemented using the **Horovod** library. A detailed explaination of how to use **Horovod** for model parallelization is provided here:\n",
    "\n",
    "**Horovod (Model Parallelization)**: https://github.com/horovod/horovod\n",
    "\n",
    "Also, we have impelemented a technique called Mixed Precision which accelerates tensors operation on GPUs with computing capability at least 7.0 and a technique called Accelerated Linear Algebra (XLA) from Tensorflow, in order to accelerate as much as possible the computation. More info can be found in the related webpages:\n",
    "\n",
    "**Mixed Precision**: https://www.tensorflow.org/guide/mixed_precision\n",
    "\n",
    "**XLA**: https://www.tensorflow.org/xla\n",
    "\n",
    "\n",
    "Luckily, we benefit of a cluster of 4 NVIDIA V100 GPUs with computing capability of 7.0.. Even in this case, sufficiently accurately results have been achieved in at least 5 months ( approximately 600 epochs required) using model parallelization and at least 3 months (approximately 400 epochs required) using model parallelization. We have realized that model parallelization is a little bit faster in both the computation and in achieving a sufficiently high performance (less epochs required).\n",
    "\n",
    "In this notebook we illustrate both the implementations.\n",
    "\n",
    "\n",
    "The main files are *training_data-parallelization.py* and *training_model-parallelization.py*.In addition, the file *fcn.py* contains the implementation of the FCN, while *training_utils.py* contains the modules to perform random imaging transormations of the input images and to calculate the R^2 between the predicted and true CHs, as well as to plot the input data in a debug folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parallelization\n",
    "\n",
    "Here we provide the code to implement the training of the FCN using data parallelization in Tensorflow 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: importing the libraries:\n",
    "\n",
    "- Numpy.\n",
    "\n",
    "- Tensorflow. In particular, we import the module mixed_precision to implement the mixed precision technique.\n",
    "\n",
    "- fcn: file containing the architecture of the FCN.\n",
    "\n",
    "- training_utils: file containing the modules for the calculation of the R^2 (R2_CHs), the implementation of the random transformations on the input images (Random_Imaging) and plotting in debug folder (plot_debug).\n",
    "\n",
    "- time, datetime: libraries to manage timing, used to calculated to processing time of the learning process in terms of images/second.\n",
    "\n",
    "- loggin,platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from fcn import FCN\n",
    "from training_utils import R2_CHs,Random_Imaging,plot_debug\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Step 2: defining the directories path to load data and save results:\n",
    "\n",
    "- **training_folder_path, test_folder_path**: paths to training and test data. The data are saved in numpy arrays data_1.npy, data_2.npy, etc. as tensors which contain both the images and the labels maps.\n",
    "\n",
    "\n",
    "- **training_results_folder_path, test_results_folder_path**: paths to the parent directories containing the saved training and test results.\n",
    "\n",
    "\n",
    "- **debug_folder_path**: path to debug directory to save the plots of the input images and labels just to check what it is going through the network.\n",
    "\n",
    "\n",
    "- **weights_folder_path**: path to the directory to save the weights of the FCN at each epoch.\n",
    "\n",
    "\n",
    "- **training_learning_curve_folder_path,test_learning_curve_folder_path**: paths to the directories containing the training and test learning curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder_path = '../training_data-try/data/'\n",
    "test_folder_path = '../test_data-try/data/'\n",
    "\n",
    "training_results_folder_path = 'results_data-parallelization/training_results/'\n",
    "debug_folder_path = training_results_folder_path + 'debug/'\n",
    "weights_folder_path = training_results_folder_path + 'weights/'\n",
    "training_learning_curve_folder_path = training_results_folder_path + 'train_learning_curve/'\n",
    "\n",
    "test_results_folder_path = 'results_data-parallelization/test_results/'\n",
    "test_learning_curve_folder_path = test_results_folder_path + 'test_learning_curve/'\n",
    "\n",
    "\n",
    "if training_results_folder_path and not os.path.exists(training_results_folder_path):\n",
    "    os.makedirs(training_results_folder_path)\n",
    "\n",
    "if debug_folder_path and not os.path.exists(debug_folder_path):\n",
    "    os.makedirs(debug_folder_path)\n",
    "\n",
    "if weights_folder_path and not os.path.exists(weights_folder_path):\n",
    "    os.makedirs(weights_folder_path)\n",
    "\n",
    "if training_learning_curve_folder_path and not os.path.exists(training_learning_curve_folder_path):\n",
    "    os.makedirs(training_learning_curve_folder_path)\n",
    "\n",
    "if test_results_folder_path and not os.path.exists(test_results_folder_path):\n",
    "    os.makedirs(test_results_folder_path)\n",
    "\n",
    "if test_learning_curve_folder_path and not os.path.exists(test_learning_curve_folder_path):\n",
    "    os.makedirs(test_learning_curve_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Step 3: defining the computing techniques: Mirrored Strategy, Mixed Precision, Config Proto and XLA\n",
    "\n",
    " - **Mirrored Strategy**: implementation of data parallelization.\n",
    " \n",
    " - **Mixed Precision**: mixed precision should be activated (mp = True) only if the cod is run on an NVIDIS GPU with a computing capability at least of 7.0. In other case, mixed precison actually slows down the calculation. \n",
    " \n",
    " - **Config Proto**: method to define server parameters for training. In particular:\n",
    " \n",
    " \n",
    "   - **allow_soft_placement**: dynamic allocation of GPU memory.\n",
    "   \n",
    "   - **log_device_placement**: printing of device information.\n",
    "   \n",
    "   - **gpu_options.allow_growth**: allowing to allocate only the memory required by the process, instead of allocating the full memory of the device where the process runs.\n",
    "   \n",
    "   - **gpu_options.force_gpu_compatible**: force all tensors to be gpu_compatible. All CPU tensors will be allocated with Cuda pinned memory.\n",
    "   \n",
    "   - **graph_options.optimizer_options.global_jit_level**: XLA activation.\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mirrored Strategy (1)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "# Mixed Precision (2)\n",
    "mp = False\n",
    "\n",
    "if mp:\n",
    "\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "\n",
    "    mixed_precision.set_policy(policy)\n",
    "\n",
    "# set gpus options\n",
    "config_proto = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config_proto.allow_soft_placement = True\n",
    "\n",
    "config_proto.log_device_placement = True\n",
    "\n",
    "config_proto.gpu_options.allow_growth = True\n",
    "\n",
    "config_proto.gpu_options.force_gpu_compatible = True\n",
    "\n",
    "# XLA (3)\n",
    "config_proto.graph_options.optimizer_options.global_jit_level = tf.compat.v1.OptimizerOptions.ON_1\n",
    "\n",
    "# session definition\n",
    "sess = tf.compat.v1.InteractiveSession(config = config_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chemical_elements = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
